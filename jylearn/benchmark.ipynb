{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The benchmark of SARCOS dataset\n",
    "\n",
    "The performance of different algorithms on this dataset can be found in: https://github.com/Kaixhin/SARCOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression with fourier(polynomial()) feature: 2.177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jylearn.data.reg_data import robot_inv_data\n",
    "import numpy as np\n",
    "import torch as th\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "Loss = th.nn.MSELoss()\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = robot_inv_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dim:  7842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:55<00:00, 11.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1766, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X, Y = np.concatenate([X_train, X_val], axis=0), np.concatenate([Y_train, Y_val], axis=0)\n",
    "from jylearn.feature.polynomial import PolynomialFT\n",
    "from jylearn.feature.fourier import FourierBases\n",
    "from jylearn.parametric.ridge import RidgeReg\n",
    "\n",
    "f1 = FourierBases(15)\n",
    "f2 = PolynomialFT(2)\n",
    "X_f = f1(f2(X))\n",
    "print(\"feature dim: \", X_f.shape[1])\n",
    "X_test_f = f1(f2(X_test))\n",
    "X_f_t, Y_t, X_test_f_t, Y_t_test = th.from_numpy(X_f).to(device), th.from_numpy(Y).to(device), th.from_numpy(X_test_f).to(device), th.from_numpy(Y_test).to(device)\n",
    "rr = RidgeReg().fit(X_f_t, Y_t)\n",
    "pred = rr.predict(X_test_f_t)\n",
    "mse = Loss(pred, Y_t_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network: 1.469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test =\\\n",
    "    th.from_numpy(X_train).to(device), th.from_numpy(Y_train).to(device), th.from_numpy(X_val).to(device), \\\n",
    "    th.from_numpy(Y_val).to(device), th.from_numpy(X_test).to(device), th.from_numpy(Y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=21, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=500, out_features=7, bias=True)\n",
      "  )\n",
      ")\n",
      "Curr validation loss:  tensor(22.8014, device='cuda:0')\n",
      "Curr validation loss:  tensor(19.0006, device='cuda:0')\n",
      "Curr validation loss:  tensor(16.6982, device='cuda:0')\n",
      "Curr validation loss:  tensor(13.5147, device='cuda:0')\n",
      "Curr validation loss:  tensor(13.6710, device='cuda:0')\n",
      "Curr validation loss:  tensor(10.9160, device='cuda:0')\n",
      "Curr validation loss:  tensor(10.5393, device='cuda:0')\n",
      "Curr validation loss:  tensor(10.2446, device='cuda:0')\n",
      "Curr validation loss:  tensor(9.8874, device='cuda:0')\n",
      "Curr validation loss:  tensor(9.7807, device='cuda:0')\n",
      "Curr validation loss:  tensor(9.4553, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.9885, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.5249, device='cuda:0')\n",
      "Curr validation loss:  tensor(9.2376, device='cuda:0')\n",
      "Curr validation loss:  tensor(9.1354, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.6088, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.5999, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.9240, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.6330, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.4300, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8112, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.3339, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8098, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.7532, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.5085, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3873, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.1617, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8857, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.5065, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4419, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.6030, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8353, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3972, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.5307, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8178, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3449, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.5083, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4069, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.5158, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4773, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3404, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8530, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8128, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1676, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1505, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1532, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1066, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8396, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4555, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.8227, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.2564, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4174, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4307, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0498, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1755, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0298, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3282, device='cuda:0')\n",
      "Curr validation loss:  tensor(8.2088, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3321, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.9436, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0588, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3675, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1844, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.4472, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.2262, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3934, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.2455, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.8465, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.7772, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1430, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.7591, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0699, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.9920, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.8468, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1069, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.9995, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.6254, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0444, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0926, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1906, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0040, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.8295, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0819, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.4780, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.3896, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.8860, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.8874, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.7876, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.6803, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.9875, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.9031, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0117, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.2953, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.8006, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.1255, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.7557, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.7179, device='cuda:0')\n",
      "Curr validation loss:  tensor(7.0827, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.6788, device='cuda:0')\n",
      "Curr validation loss:  tensor(6.6788, device='cuda:0')\n",
      "tensor(1.4686, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "from jylearn.parametric.mlp import MLP\n",
    "param = {\"layer\":4, \"nodes\":[21, 500, 500, 7], \"batch\":128, \"lr\":1e-3, \"decay\":0.}\n",
    "net = MLP(param).to(device)\n",
    "print(net)\n",
    "Loss = MSELoss()\n",
    "parameters = MLP.setParams(net, param[\"decay\"])\n",
    "optimizer = Adam(parameters, lr=param[\"lr\"])\n",
    "for _ in range(100):\n",
    "    for i in range(len(X_train)//param[\"batch\"]):\n",
    "        optimizer.zero_grad()\n",
    "        index = th.randperm(len(X_train))\n",
    "        curr_index = index[i*param[\"batch\"]:(i+1)*param[\"batch\"]]\n",
    "        X_b = X_train[curr_index]\n",
    "        Y_b = Y_train[curr_index]\n",
    "        pred = net(X_b)\n",
    "        L = Loss(pred, Y_b)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    with th.no_grad():\n",
    "        pred_val = net(X_val)\n",
    "        L_val = Loss(pred_val, Y_val)\n",
    "        print(\"Curr validation loss: \", L_val)\n",
    "net.eval()\n",
    "pred_test = net(X_test)\n",
    "print(Loss(pred_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
