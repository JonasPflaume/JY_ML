{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The benchmark of SARCOS dataset\n",
    "\n",
    "The performance of different algorithms on this dataset can be found in: https://github.com/Kaixhin/SARCOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression with fourier(polynomial()) feature: 2.111,  \n",
    "NN feature not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jylearn.data.get_data import robot_inv_data\n",
    "import numpy as np\n",
    "import torch as th\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "Loss = th.nn.MSELoss()\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = robot_inv_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.concatenate([X_train, X_val], axis=0), np.concatenate([Y_train, Y_val], axis=0)\n",
    "from jylearn.feature.polynomial import PolynomialFT\n",
    "from jylearn.feature.bellcurve import BellCurve\n",
    "from jylearn.feature.fourier import FourierBases\n",
    "from jylearn.parametric.ridge import RidgeReg\n",
    "\n",
    "param1 = np.linspace(0.05, 0.99, 7)\n",
    "param2 = np.arange(1, 7)\n",
    "\n",
    "f1 = FourierBases(param1, param2)\n",
    "f2 = PolynomialFT(2)\n",
    "\n",
    "X_f = f1(f2(X))\n",
    "X_test_f = f1(f2(X_test))\n",
    "print(\"feature dim: \", X_f.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f_t, Y_t, X_test_f_t, Y_t_test = th.from_numpy(X_f).to(device), th.from_numpy(Y).to(device), th.from_numpy(X_test_f).to(device), th.from_numpy(Y_test).to(device)\n",
    "rr = RidgeReg().fit(X_f_t, Y_t)\n",
    "pred = rr.predict(X_test_f_t)\n",
    "mse = Loss(pred, Y_t_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test =\\\n",
    "    th.from_numpy(X_train).to(device).double(), th.from_numpy(Y_train).to(device).double(), th.from_numpy(X_val).to(device).double(), \\\n",
    "    th.from_numpy(Y_val).to(device).double(), th.from_numpy(X_test).to(device).double(), th.from_numpy(Y_test).to(device).double()\n",
    "    \n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "from jylearn.parametric.mlp import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network: 1.469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"layer\":4, \"nodes\":[21, 500, 500, 7], \"actfunc\":[\"ReLU\", \"ReLU\", None], \"batch\":128, \"lr\":1e-3, \"decay\":0.}\n",
    "net = MLP(param).to(device).double()\n",
    "print(net)\n",
    "Loss = MSELoss()\n",
    "parameters = MLP.setParams(net, param[\"decay\"])\n",
    "optimizer = Adam(parameters, lr=param[\"lr\"])\n",
    "for _ in range(100):\n",
    "    for i in range(len(X_train)//param[\"batch\"]):\n",
    "        optimizer.zero_grad()\n",
    "        index = th.randperm(len(X_train))\n",
    "        curr_index = index[i*param[\"batch\"]:(i+1)*param[\"batch\"]]\n",
    "        X_b = X_train[curr_index]\n",
    "        Y_b = Y_train[curr_index]\n",
    "        pred = net(X_b)\n",
    "        L = Loss(pred, Y_b)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    with th.no_grad():\n",
    "        pred_val = net(X_val)\n",
    "        L_val = Loss(pred_val, Y_val)\n",
    "        print(\"Curr validation loss: \", L_val)\n",
    "net.eval()\n",
    "pred_test = net(X_test)\n",
    "print(Loss(pred_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample GPR with hyperparameters optimization: 2.887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jylearn.nonparametric.gpr import ExactGPR\n",
    "from jylearn.kernel.kernels import White, RQK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = X_test.double(), Y_test.double()\n",
    "perm = th.randperm(X_train.size(0))\n",
    "idx = perm[:5000]\n",
    "X_train_, Y_train_ = X_train[idx].double(), Y_train[idx].double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.ones((21,7)) * 30.\n",
    "sigma = np.ones((7,)) * 1.\n",
    "c = np.ones((7,)) * 1.\n",
    "\n",
    "kernel = White(c=c, dim_in=21, dim_out=7) + RQK(l=l, sigma=sigma, alpha=sigma, dim_in=21, dim_out=7)\n",
    "gpr = ExactGPR(kernel=kernel)\n",
    "gpr.fit(X_train_, Y_train_, call_hyper_opt=True, lr=0.05, epoch=9000, optimizer_type=\"RMSPROP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gpr.predict(X_test)\n",
    "print(Loss(pred, Y_test))\n",
    "\n",
    "del gpr, pred, kernel\n",
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titsias' variational EM GPR: m=250, 2.8788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jylearn.nonparametric.vigpr import VariationalEMSparseGPR\n",
    "from jylearn.kernel.kernels import White, RBF\n",
    "\n",
    "l = np.ones([21, 1]) * 1.\n",
    "sigma = np.ones([1,]) * 1.\n",
    "c = np.ones([1,]) * 0.1\n",
    "\n",
    "white_kernel = White(c=c, dim_in=21, dim_out=1)\n",
    "kernel = RBF(sigma=sigma, l=l, dim_in=21, dim_out=1)\n",
    "\n",
    "gpr = VariationalEMSparseGPR(kernel=kernel, white_kernle=white_kernel)\n",
    "ind = gpr.fit(X_train, Y_train, m=20, subsetNum=100, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gpr.predict(X_test)\n",
    "print(Loss(pred, Y_test))\n",
    "\n",
    "del gpr, pred, kernel\n",
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
